# Examples
We provide some running examples. We will update the examples if we achieve better results on large games such as Dou Dizhu, UNO and Mahjong.

*   `blackjack_dqn.py`: train DQN on Blackjack.
*   `blackjack_dqn_multi_process.py`: train DQN on Blackjack with multiple processes.
*   `blackjack_random.py`: run random agents on Blackjcak.
*   `doudizhu_dqn.py`: train DQN on Dou Dizhu.
*   `doudizhu_nfsp.py`: train NFSP on Dou Dizhu.
*   `doudizhu_random.py`: run random agents on Dou Dizhu.
*   `doudizhu_random_multi_process.py`: run random agents on Dou Dizhu with multiple processes.
*   `doudizhu_random_process_pool.py`:run random agents on Dou Dizhu with multiple processes using process pool.
*   `leduc_holdem_dqn.py`: train DQN on Leduc Hold'em.
*   `leduc_holdem_human.py`: play against re-trained model on Leduc Hold'em.
*   `leduc_holdem_nfsp.py`: train NFSP on Leduc Hold'em.
*   `leduc_holdem_random.py`: run random agents on Leduc Hold'em.
*   `leduc_holdem_single.py`: train DQN on Leduc Hold'em as single-agent environment.
*   `limit_holdem_dqn.py`: train DQN on Limit Texas Hold'em.
*   `limit_holdem_nfsp.py`: train NFSP on Limit Texas Hold'em.
*   `limit_holdem_random.py`: run random agents on Limit Texas Hold'em.
*   `mahjong_dqn.py`: train DQN on Mahjong.
*   `mahjong_nfsp.py`: train NFSP on Mahjong.
*   `mahjong_random.py`: run random agents on Mahjong.
*   `nolimit_holdem_dqn.py`: train DQN on No-Limit Texas Hold'em.
*   `nolimit_holdem_nfsp.py`: train NFSP on No-Limit Texas Hold'em.
*   `nolimit_holdem_random.py`: run random agents on No-Limit Gexas Hold'em.
*   `uno_dqn.py`: train DQN on UNO.
*   `uno_human.py`: play against rule-based model on UNO.
*   `uno_nfsp.py`: train NFSP on UNO.
*   `uno_random.py`: run random agents on UNO.
*   `uno_single.py`: train DQN on UNO as single-agent environment.
